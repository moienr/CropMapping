{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"execution":{"iopub.execute_input":"2023-10-23T12:53:06.438498Z","iopub.status.busy":"2023-10-23T12:53:06.438139Z","iopub.status.idle":"2023-10-23T12:53:06.445192Z","shell.execute_reply":"2023-10-23T12:53:06.444307Z","shell.execute_reply.started":"2023-10-23T12:53:06.438470Z"},"trusted":true},"outputs":[{"data":{"text/plain":["False"]},"execution_count":1,"metadata":{},"output_type":"execute_result"}],"source":["import os\n","IN_KAGGLE = 'KAGGLE_URL_BASE' in os.environ\n","IN_KAGGLE"]},{"cell_type":"code","execution_count":2,"metadata":{"execution":{"iopub.execute_input":"2023-10-23T12:53:07.270998Z","iopub.status.busy":"2023-10-23T12:53:07.270302Z","iopub.status.idle":"2023-10-23T12:53:08.482012Z","shell.execute_reply":"2023-10-23T12:53:08.480913Z","shell.execute_reply.started":"2023-10-23T12:53:07.270966Z"},"trusted":true},"outputs":[],"source":["if IN_KAGGLE:\n","    from kaggle_secrets import UserSecretsClient\n","    user_secrets = UserSecretsClient()\n","    secret_value = user_secrets.get_secret(\"gittoken2\")\n","    !git clone https://{secret_value}@github.com/moienr/CropMapping.git"]},{"cell_type":"code","execution_count":3,"metadata":{"execution":{"iopub.execute_input":"2023-10-23T12:53:08.484582Z","iopub.status.busy":"2023-10-23T12:53:08.484297Z","iopub.status.idle":"2023-10-23T12:53:08.491183Z","shell.execute_reply":"2023-10-23T12:53:08.490184Z","shell.execute_reply.started":"2023-10-23T12:53:08.484555Z"},"trusted":true},"outputs":[],"source":["if IN_KAGGLE:\n","    import time\n","    import os\n","    sleep_time = 5\n","    while not os.path.exists(\"/kaggle/working/CropMapping\"):\n","        print(\"didn't find the path, wating {sleep_time} more seconds...\")\n","        time.sleep(sleep_time)\n","    print(\"path found...\")\n","    import sys\n","    sys.path.append(\"/kaggle/working/CropMapping\")\n","    sys.path.append(\"/kaggle/working/CropMapping/dataset\")"]},{"cell_type":"code","execution_count":4,"metadata":{"execution":{"iopub.execute_input":"2023-10-23T12:53:09.100621Z","iopub.status.busy":"2023-10-23T12:53:09.100279Z","iopub.status.idle":"2023-10-23T12:53:09.105813Z","shell.execute_reply":"2023-10-23T12:53:09.104751Z","shell.execute_reply.started":"2023-10-23T12:53:09.100592Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["c:\\Users\\moi3n\\miniconda3\\envs\\pytorchGPU\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n","  from .autonotebook import tqdm as notebook_tqdm\n"]}],"source":["import torch\n","# import albumentations as A\n","# from albumentations.pytorch import ToTensorV2\n","from tqdm import tqdm\n","import torch.nn as nn\n","import torch.optim as optim\n","# from model import UNET\n","# from utils import (\n","#     load_checkpoint,\n","#     save_checkpoint,\n","#     check_accuracy,\n","#     save_predictions_as_imgs,\n","# )\n"]},{"cell_type":"code","execution_count":5,"metadata":{"execution":{"iopub.execute_input":"2023-10-23T12:53:10.174620Z","iopub.status.busy":"2023-10-23T12:53:10.174259Z","iopub.status.idle":"2023-10-23T12:53:10.180775Z","shell.execute_reply":"2023-10-23T12:53:10.179906Z","shell.execute_reply.started":"2023-10-23T12:53:10.174593Z"},"trusted":true},"outputs":[{"data":{"text/plain":["'1.13.1'"]},"execution_count":5,"metadata":{},"output_type":"execute_result"}],"source":["import torch\n","torch.__version__"]},{"cell_type":"code","execution_count":6,"metadata":{"execution":{"iopub.execute_input":"2023-10-23T12:53:10.525748Z","iopub.status.busy":"2023-10-23T12:53:10.525000Z","iopub.status.idle":"2023-10-23T12:53:10.534378Z","shell.execute_reply":"2023-10-23T12:53:10.533411Z","shell.execute_reply.started":"2023-10-23T12:53:10.525711Z"},"trusted":true},"outputs":[{"data":{"text/plain":["20"]},"execution_count":6,"metadata":{},"output_type":"execute_result"}],"source":["import numpy as np\n","from torch.utils.data import Dataset\n","import torch.nn.functional as F\n","from glob import glob\n","from skimage import io\n","import os\n","from torchvision import datasets, transforms\n","import matplotlib\n","import os\n","import gc\n","import random\n","from datetime import date, datetime\n","import json\n","import pprint\n","os.cpu_count()"]},{"cell_type":"code","execution_count":7,"metadata":{"execution":{"iopub.execute_input":"2023-10-23T12:53:11.313328Z","iopub.status.busy":"2023-10-23T12:53:11.312955Z","iopub.status.idle":"2023-10-23T12:53:11.317778Z","shell.execute_reply":"2023-10-23T12:53:11.316871Z","shell.execute_reply.started":"2023-10-23T12:53:11.313300Z"},"trusted":true},"outputs":[],"source":["from model.model import DualUNet3D"]},{"cell_type":"code","execution_count":8,"metadata":{"execution":{"iopub.execute_input":"2023-10-23T12:53:11.968704Z","iopub.status.busy":"2023-10-23T12:53:11.968358Z","iopub.status.idle":"2023-10-23T12:53:11.975125Z","shell.execute_reply":"2023-10-23T12:53:11.974154Z","shell.execute_reply.started":"2023-10-23T12:53:11.968674Z"},"trusted":true},"outputs":[{"data":{"text/plain":["'cuda'"]},"execution_count":8,"metadata":{},"output_type":"execute_result"}],"source":["DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n","DEVICE"]},{"cell_type":"code","execution_count":9,"metadata":{"execution":{"iopub.execute_input":"2023-10-23T12:53:12.682760Z","iopub.status.busy":"2023-10-23T12:53:12.681756Z","iopub.status.idle":"2023-10-23T12:53:13.277592Z","shell.execute_reply":"2023-10-23T12:53:13.276618Z","shell.execute_reply.started":"2023-10-23T12:53:12.682723Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Testing DualUNet3D...\n","Device: cuda\n","Shape of s1_img: torch.Size([3, 2, 6, 64, 64])\n","Shape of s2_img: torch.Size([3, 9, 6, 64, 64])\n","Shape of preds: torch.Size([3, 10, 64, 64])\n","Success!\n"]}],"source":["def test_dual_unet_3d():\n","    print(\"Testing DualUNet3D...\")\n","    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","    print(f\"Device: {device}\")\n","    s1_img = torch.randn((3, 2, 6, 64, 64)).to(device)\n","    s2_img = torch.randn((3, 9, 6, 64, 64)).to(device)\n","    model = DualUNet3D(s1_in_channels=2, s2_in_channels=9).to(device)\n","    preds = model(s1_img, s2_img)\n","    print(f\"Shape of s1_img: {s1_img.shape}\")\n","    print(f\"Shape of s2_img: {s2_img.shape}\")\n","    print(f\"Shape of preds: {preds.shape}\")\n","    print(\"Success!\")\n","\n","test_dual_unet_3d()"]},{"cell_type":"code","execution_count":10,"metadata":{"execution":{"iopub.execute_input":"2023-10-23T12:53:13.429471Z","iopub.status.busy":"2023-10-23T12:53:13.429158Z","iopub.status.idle":"2023-10-23T12:53:13.434804Z","shell.execute_reply":"2023-10-23T12:53:13.433847Z","shell.execute_reply.started":"2023-10-23T12:53:13.429444Z"},"trusted":true},"outputs":[],"source":["# from dataset.data_loaders import *\n","# from dataset.utils.utils import TextColors as TC\n","# from dataset.utils.plot_utils import plot_s1s2_tensors, save_s1s2_tensors_plot\n","# #from config import *\n","# from train_utils import *"]},{"cell_type":"code","execution_count":11,"metadata":{"execution":{"iopub.execute_input":"2023-10-23T12:53:13.789328Z","iopub.status.busy":"2023-10-23T12:53:13.788716Z","iopub.status.idle":"2023-10-23T12:53:13.793969Z","shell.execute_reply":"2023-10-23T12:53:13.792894Z","shell.execute_reply.started":"2023-10-23T12:53:13.789298Z"},"trusted":true},"outputs":[],"source":["import torch.nn as nn\n","import torch.optim as optim\n","from torch.utils.data import DataLoader"]},{"cell_type":"code","execution_count":12,"metadata":{"execution":{"iopub.execute_input":"2023-10-23T12:53:14.209704Z","iopub.status.busy":"2023-10-23T12:53:14.209412Z","iopub.status.idle":"2023-10-23T12:53:14.213957Z","shell.execute_reply":"2023-10-23T12:53:14.212908Z","shell.execute_reply.started":"2023-10-23T12:53:14.209679Z"},"trusted":true},"outputs":[],"source":["from dataset.data_loaders import *\n","from plot import plot_train_test_losses"]},{"cell_type":"code","execution_count":13,"metadata":{"execution":{"iopub.execute_input":"2023-10-23T12:53:14.652187Z","iopub.status.busy":"2023-10-23T12:53:14.651815Z","iopub.status.idle":"2023-10-23T12:53:14.657391Z","shell.execute_reply":"2023-10-23T12:53:14.656517Z","shell.execute_reply.started":"2023-10-23T12:53:14.652159Z"},"trusted":true},"outputs":[],"source":["s1_transform = transforms.Compose([NormalizeS1(),myToTensor(dtype=torch.float32)])\n","s2_transform = transforms.Compose([NormalizeS2(),myToTensor(dtype=torch.float32)])\n","crop_map_transform = transforms.Compose([CropMapTransform(),myToTensor(dtype=torch.float32)])"]},{"cell_type":"code","execution_count":14,"metadata":{"execution":{"iopub.execute_input":"2023-10-23T12:54:11.182290Z","iopub.status.busy":"2023-10-23T12:54:11.181921Z","iopub.status.idle":"2023-10-23T12:54:11.188379Z","shell.execute_reply":"2023-10-23T12:54:11.187303Z","shell.execute_reply.started":"2023-10-23T12:54:11.182261Z"},"trusted":true},"outputs":[],"source":["# Train Paths\n","if IN_KAGGLE:\n","    s1_dir = \"/kaggle/input/francedatasetv1/s1/\"\n","    s2_dir = \"/kaggle/input/francedatasetv1/s2/\"\n","    crop_map_dir = \"/kaggle/input/francedatasetv1/crop_map/\"\n","else:\n","    s1_dir = \"D:\\\\python\\\\CropMapping\\\\dataset\\\\ts_dataset_patched\\\\s1\\\\\"\n","    s2_dir = \"D:\\\\python\\\\CropMapping\\\\dataset\\\\ts_dataset_patched\\\\s2\\\\\"\n","    crop_map_dir = \"D:\\\\python\\\\CropMapping\\\\dataset\\\\ts_dataset_patched\\\\crop_map\\\\\"\n","    \n","# Validation Paths\n","if IN_KAGGLE:\n","    s1_dir_valid = \"/kaggle/input/france-valid-dataset-v1/s1/\"\n","    s2_dir_valid = \"/kaggle/input/france-valid-dataset-v1/s2/\"\n","    crop_map_dir_valid = \"/kaggle/input/france-valid-dataset-v1/crop_map/\"\n","else:\n","    s1_dir_valid = \"D:\\\\python\\\\CropMapping\\\\dataset\\\\ts_dataset_patched\\\\s1\\\\\"\n","    s2_dir_valid = \"D:\\\\python\\\\CropMapping\\\\dataset\\\\ts_dataset_patched\\\\s2\\\\\"\n","    crop_map_dir_valid = \"D:\\\\python\\\\CropMapping\\\\dataset\\\\ts_dataset_patched\\\\crop_map\\\\\"\n","    "]},{"cell_type":"code","execution_count":15,"metadata":{"execution":{"iopub.execute_input":"2023-10-23T12:54:12.452176Z","iopub.status.busy":"2023-10-23T12:54:12.451558Z","iopub.status.idle":"2023-10-23T12:54:30.136006Z","shell.execute_reply":"2023-10-23T12:54:30.134991Z","shell.execute_reply.started":"2023-10-23T12:54:12.452145Z"},"trusted":true},"outputs":[],"source":["train_dataset = Sen12Dataset(s1_dir=s1_dir,\n","                            s2_dir=s2_dir,\n","                            crop_map_dir=crop_map_dir,\n","                            s1_transform=s1_transform,\n","                            s2_transform=s2_transform,\n","                            crop_map_transform=crop_map_transform,\n","                            verbose=False)\n","\n","valid_dataset = Sen12Dataset(s1_dir=s1_dir_valid,\n","                            s2_dir=s2_dir_valid,\n","                            crop_map_dir=crop_map_dir_valid,\n","                            s1_transform=s1_transform,\n","                            s2_transform=s2_transform,\n","                            crop_map_transform=crop_map_transform,\n","                            verbose=False)"]},{"cell_type":"code","execution_count":16,"metadata":{"execution":{"iopub.execute_input":"2023-10-23T12:54:30.138407Z","iopub.status.busy":"2023-10-23T12:54:30.138041Z","iopub.status.idle":"2023-10-23T12:54:30.369791Z","shell.execute_reply":"2023-10-23T12:54:30.368748Z","shell.execute_reply.started":"2023-10-23T12:54:30.138374Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["torch.Size([2, 6, 64, 64]) torch.Size([10, 6, 64, 64]) torch.Size([21, 64, 64])\n","torch.Size([2, 6, 64, 64]) torch.Size([10, 6, 64, 64]) torch.Size([21, 64, 64])\n"]}],"source":["print(train_dataset[0][0].shape, train_dataset[0][1].shape, train_dataset[0][2].shape)\n","print(valid_dataset[0][0].shape, valid_dataset[0][1].shape, valid_dataset[0][2].shape)\n"]},{"cell_type":"code","execution_count":17,"metadata":{"execution":{"iopub.execute_input":"2023-10-23T12:54:30.371793Z","iopub.status.busy":"2023-10-23T12:54:30.371177Z","iopub.status.idle":"2023-10-23T12:54:30.375994Z","shell.execute_reply":"2023-10-23T12:54:30.375117Z","shell.execute_reply.started":"2023-10-23T12:54:30.371757Z"},"trusted":true},"outputs":[],"source":["BATCH_SIZE = 16 if IN_KAGGLE else 4"]},{"cell_type":"code","execution_count":18,"metadata":{"execution":{"iopub.execute_input":"2023-10-23T12:54:30.378330Z","iopub.status.busy":"2023-10-23T12:54:30.378065Z","iopub.status.idle":"2023-10-23T12:54:30.392029Z","shell.execute_reply":"2023-10-23T12:54:30.391083Z","shell.execute_reply.started":"2023-10-23T12:54:30.378306Z"},"trusted":true},"outputs":[],"source":["train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=2)\n","valid_loader = DataLoader(valid_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=2)"]},{"cell_type":"code","execution_count":19,"metadata":{"execution":{"iopub.execute_input":"2023-10-23T12:54:30.393208Z","iopub.status.busy":"2023-10-23T12:54:30.392956Z","iopub.status.idle":"2023-10-23T12:54:30.407614Z","shell.execute_reply":"2023-10-23T12:54:30.406541Z","shell.execute_reply.started":"2023-10-23T12:54:30.393182Z"},"trusted":true},"outputs":[{"data":{"text/plain":["57"]},"execution_count":19,"metadata":{},"output_type":"execute_result"}],"source":["len(train_loader)"]},{"cell_type":"code","execution_count":20,"metadata":{"execution":{"iopub.execute_input":"2023-10-23T12:54:30.409144Z","iopub.status.busy":"2023-10-23T12:54:30.408788Z","iopub.status.idle":"2023-10-23T12:54:31.004387Z","shell.execute_reply":"2023-10-23T12:54:31.002827Z","shell.execute_reply.started":"2023-10-23T12:54:30.409117Z"},"trusted":true},"outputs":[],"source":["model = DualUNet3D(s1_in_channels=2, s2_in_channels=10, out_channels=21,ts_depth=6,non_lin='sigmoid').to(DEVICE)"]},{"cell_type":"code","execution_count":21,"metadata":{"execution":{"iopub.execute_input":"2023-10-23T12:58:15.821217Z","iopub.status.busy":"2023-10-23T12:58:15.820509Z","iopub.status.idle":"2023-10-23T12:58:15.830052Z","shell.execute_reply":"2023-10-23T12:58:15.829104Z","shell.execute_reply.started":"2023-10-23T12:58:15.821182Z"},"trusted":true},"outputs":[],"source":["def train_step(model, train_loader, criterion, optimizer, epoch, verbose=True):\n","    \"\"\"\n","    Train the model for one epoch\n","    \n","    Args:\n","    - model: the model to train\n","    - train_loader: the data loader for the training data\n","    - criterion: the loss function\n","    - optimizer: the optimizer\n","    - epoch: the current epoch\n","    \n","    Returns:\n","    - None\n","    \"\"\"\n","    # Set the model to train mode\n","    model.train()\n","    train_loss = 0\n","    num_batches = len(train_loader)\n","    # Loop over the data in the train loader\n","    for batch_idx, (s1, s2, crop_map) in enumerate(train_loader):\n","\n","        # Move the data to the device\n","        s1, s2, crop_map = s1.to(DEVICE), s2.to(DEVICE), crop_map.to(DEVICE)\n","        # print(f\"s1.shape: {s1.shape}\", f\"s2.shape: {s2.shape}\", f\"crop_map.shape: {crop_map.shape}\")\n","        # Zero the gradients\n","        optimizer.zero_grad()\n","\n","        # Forward pass\n","        outputs = model(s1, s2)\n","\n","        # Calculate the loss\n","        loss = criterion(outputs, crop_map)\n","        train_loss += loss.item()\n","\n","        # Backward pass\n","        loss.backward()\n","\n","        # Update the weights\n","        optimizer.step()\n","\n","        if verbose:\n","            # Print the loss\n","            print(f'Train Epoch: {epoch} [{batch_idx * len(s1)}/{len(train_loader.dataset)} '\n","                f'({100. * batch_idx / len(train_loader):.0f}%)]\\tLoss: {loss.item():.6f}')\n","        \n","    train_loss /= num_batches\n","    return train_loss\n"]},{"cell_type":"code","execution_count":22,"metadata":{"execution":{"iopub.execute_input":"2023-10-23T12:58:17.093519Z","iopub.status.busy":"2023-10-23T12:58:17.093162Z","iopub.status.idle":"2023-10-23T12:58:17.100755Z","shell.execute_reply":"2023-10-23T12:58:17.099822Z","shell.execute_reply.started":"2023-10-23T12:58:17.093490Z"},"trusted":true},"outputs":[],"source":["def valid_step(model, valid_loader, criterion):\n","    \"\"\"\n","    Evaluate the model on the validation set\n","    \n","    Args:\n","    - model: the model to evaluate\n","    - valid_loader: the data loader for the validation data\n","    - criterion: the loss function\n","    \n","    Returns:\n","    - val_loss: the average validation loss\n","    \"\"\"\n","    # Set the model to evaluation mode\n","    model.eval()\n","\n","    # Initialize the loss and number of samples\n","    val_loss = 0.0\n","    num_batches = len(valid_loader)\n","\n","    # Disable gradient computation\n","    with torch.no_grad():\n","        # Loop over the data in the validation loader\n","        for s1, s2, crop_map in valid_loader:\n","            # Move the data to the device\n","            s1, s2, crop_map = s1.to(DEVICE), s2.to(DEVICE), crop_map.to(DEVICE)\n","\n","            # Forward pass\n","            outputs = model(s1, s2)\n","\n","            # Calculate the loss\n","            loss = criterion(outputs, crop_map)\n","\n","            # Update the loss and number of samples\n","            val_loss += loss.item() \n","\n","\n","    # Calculate the average validation loss\n","    val_loss /= num_batches\n","\n","    return val_loss\n"]},{"cell_type":"code","execution_count":23,"metadata":{"execution":{"iopub.execute_input":"2023-10-23T12:58:17.661918Z","iopub.status.busy":"2023-10-23T12:58:17.661548Z","iopub.status.idle":"2023-10-23T12:58:17.668287Z","shell.execute_reply":"2023-10-23T12:58:17.667245Z","shell.execute_reply.started":"2023-10-23T12:58:17.661883Z"},"trusted":true},"outputs":[],"source":["criterion = nn.CrossEntropyLoss()\n","optimizer = optim.Adam(model.parameters(), lr=0.001)"]},{"cell_type":"code","execution_count":24,"metadata":{"execution":{"iopub.execute_input":"2023-10-23T12:58:19.829948Z","iopub.status.busy":"2023-10-23T12:58:19.829120Z","iopub.status.idle":"2023-10-23T12:58:19.833829Z","shell.execute_reply":"2023-10-23T12:58:19.832879Z","shell.execute_reply.started":"2023-10-23T12:58:19.829909Z"},"trusted":true},"outputs":[],"source":["# train_step(model, train_loader, criterion, optimizer, 1)"]},{"cell_type":"code","execution_count":25,"metadata":{},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","from torch.optim.lr_scheduler import StepLR, ReduceLROnPlateau\n","from tqdm import tqdm\n","\n","def train(model, train_loader, valid_loader, criterion, optimizer, scheduler_type, num_epochs, **kwargs):\n","    \"\"\"\n","    Train the model with a learning rate scheduler\n","    \n","    Args:\n","    - model: the model to train\n","    - train_loader: the data loader for the training data\n","    - valid_loader: the data loader for the validation data\n","    - criterion: the loss function\n","    - optimizer: the optimizer\n","    - scheduler_type: the type of learning rate scheduler (\"constant\", \"step\", \"plateau\")\n","    - num_epochs: the number of epochs to train for\n","    \n","    Returns:\n","    - results: a dictionary containing training and validation loss histories\n","    \"\"\"\n","    results = {\n","        \"train_loss_history\": [],\n","        \"val_loss_history\": []\n","    }\n","    \n","    progress_bar = tqdm(range(num_epochs), desc=\"Training\", unit=\"epoch\")\n","    \n","    if scheduler_type == \"step\":\n","        step_size = kwargs[\"step_size\"]\n","        gamma = kwargs[\"gamma\"]\n","        scheduler = StepLR(optimizer, step_size=step_size, gamma=gamma)\n","    elif scheduler_type == \"plateau\":\n","        factor = kwargs[\"factor\"]\n","        patience = kwargs[\"patience\"]\n","        scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=factor, patience=patience, verbose=True)\n","    else:\n","        scheduler = None\n","    \n","    for epoch in progress_bar:\n","        train_loss = train_step(model, train_loader, criterion, optimizer, epoch + 1, verbose=False)\n","        val_loss = valid_step(model, valid_loader, criterion)\n","        \n","        results[\"train_loss_history\"].append(train_loss)\n","        results[\"val_loss_history\"].append(val_loss)\n","        \n","        progress_bar.set_postfix({\"Epoch\": epoch + 1, \"Train Loss\": train_loss, \"Validation Loss\": val_loss})\n","        \n","        # Step the learning rate scheduler\n","        if scheduler == \"step\":\n","            scheduler.step()\n","        elif scheduler == \"plateau\":\n","            scheduler.step(val_loss)\n","        else:\n","            pass\n","        \n","    return results\n","\n","\n","\n","\n"]},{"cell_type":"code","execution_count":29,"metadata":{},"outputs":[],"source":["# Example usage\n","learning_rate = 0.01\n","optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n","scheduler_type = \"plateau\"  # Options: \"constant\", \"step\", \"plateau\". Choose which scheduler to use.\n","\n","if scheduler_type == \"step\":\n","    step_size = 5\n","    gamma = 0.2\n","    scheduler_kwargs = {\"step_size\": step_size, \"gamma\": gamma}\n","elif scheduler_type == \"plateau\":\n","    factor = 0.5\n","    patience = 3\n","    scheduler_kwargs = {\"factor\": factor, \"patience\": patience}\n","\n","\n","NUM_EPOCH = 5\n","\n"]},{"cell_type":"code","execution_count":30,"metadata":{"execution":{"iopub.execute_input":"2023-10-23T12:58:21.212320Z","iopub.status.busy":"2023-10-23T12:58:21.211957Z","iopub.status.idle":"2023-10-23T14:12:32.352943Z","shell.execute_reply":"2023-10-23T14:12:32.350221Z","shell.execute_reply.started":"2023-10-23T12:58:21.212291Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["Training: 100%|██████████| 5/5 [00:48<00:00,  9.73s/epoch, Epoch=5, Train Loss=2.19, Validation Loss=2.18]\n"]}],"source":["results = train(model, train_loader, valid_loader, criterion, optimizer, scheduler_type, NUM_EPOCH, **scheduler_kwargs)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-10-23T15:26:49.174140Z","iopub.status.busy":"2023-10-23T15:26:49.173477Z","iopub.status.idle":"2023-10-23T15:26:49.651782Z","shell.execute_reply":"2023-10-23T15:26:49.650767Z","shell.execute_reply.started":"2023-10-23T15:26:49.174101Z"},"trusted":true},"outputs":[],"source":["torch.save(model, f\"DualUNet3D_epoch{NUM_EPOCH}_France.pth\")"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-10-23T14:12:44.591665Z","iopub.status.busy":"2023-10-23T14:12:44.591313Z","iopub.status.idle":"2023-10-23T14:12:44.596815Z","shell.execute_reply":"2023-10-23T14:12:44.595892Z","shell.execute_reply.started":"2023-10-23T14:12:44.591630Z"},"trusted":true},"outputs":[],"source":["# list to array with shape (1, len(list))\n","train_loss_history = np.array(results[\"train_loss_history\"]).reshape(1, -1)\n","val_loss_history = np.array(results[\"val_loss_history\"]).reshape(1, -1)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-10-23T14:12:44.598385Z","iopub.status.busy":"2023-10-23T14:12:44.598054Z","iopub.status.idle":"2023-10-23T14:12:44.989738Z","shell.execute_reply":"2023-10-23T14:12:44.988805Z","shell.execute_reply.started":"2023-10-23T14:12:44.598352Z"},"trusted":true},"outputs":[],"source":["plot_train_test_losses(train_loss_history, val_loss_history)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-10-23T15:29:52.112765Z","iopub.status.busy":"2023-10-23T15:29:52.111534Z","iopub.status.idle":"2023-10-23T15:29:53.034117Z","shell.execute_reply":"2023-10-23T15:29:53.032576Z","shell.execute_reply.started":"2023-10-23T15:29:52.112716Z"},"trusted":true},"outputs":[],"source":["batch = next(iter(valid_loader))\n","s1_img = batch[0].to(DEVICE)\n","s2_img = batch[1].to(DEVICE)    \n","crop_map = batch[2].to(DEVICE)\n","print(f\"s1_img.shape: {s1_img.shape}\", f\"s2_img.shape: {s2_img.shape}\", f\"crop_map.shape: {crop_map.shape}\")\n","output = model(s1_img, s2_img)\n","print(f\"output.shape: {output.shape}\")"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-10-23T15:29:53.288390Z","iopub.status.busy":"2023-10-23T15:29:53.288051Z","iopub.status.idle":"2023-10-23T15:29:53.297014Z","shell.execute_reply":"2023-10-23T15:29:53.295898Z","shell.execute_reply.started":"2023-10-23T15:29:53.288361Z"},"trusted":true},"outputs":[],"source":["import matplotlib.pyplot as plt\n","\n","def plot_s2_img(s2_img, n, m):\n","    \"\"\"\n","    Plot an image for each depth of the s2_img tensor, by plotting the first 3 channels as an RGB image.\n","    \n","    Args:\n","    - s2_img: a tensor of shape (D, C, H, W)\n","    - n: number of rows in the subplot\n","    - m: number of columns in the subplot\n","    \n","    Returns:\n","    - None\n","    \"\"\"\n","    # Move the tensor to the CPU and detach it\n","    s2_img = s2_img.cpu().detach()\n","    \n","    # Permute the tensor to have shape (D, H, W, C)\n","    s2_img = s2_img.permute(1, 2, 3, 0)\n","    \n","    # Create a new figure\n","    fig = plt.figure(figsize=(m*5, n*5))\n","    \n","    # Loop over the depths and plot an image for each depth\n","    for d in range(s2_img.shape[0]):\n","        # Extract the first 3 channels as an RGB image\n","        rgb_img = s2_img[d, :, :, :3]\n","        # reveser rgb channels\n","        rgb_img = rgb_img[:, :, [2, 1, 0]]\n","        \n","        # Plot the RGB image in a subplot\n","        ax = fig.add_subplot(n, m, d+1)\n","        ax.imshow(rgb_img)\n","        ax.set_title(f\"Depth {d}\")\n","    \n","    # Show the plot\n","    plt.show()\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-10-23T15:29:53.299355Z","iopub.status.busy":"2023-10-23T15:29:53.298992Z","iopub.status.idle":"2023-10-23T15:29:53.310643Z","shell.execute_reply":"2023-10-23T15:29:53.309820Z","shell.execute_reply.started":"2023-10-23T15:29:53.299322Z"},"trusted":true},"outputs":[],"source":["INDEX_IN_BATCH = 0"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-10-23T15:29:53.313305Z","iopub.status.busy":"2023-10-23T15:29:53.312415Z","iopub.status.idle":"2023-10-23T15:29:54.403141Z","shell.execute_reply":"2023-10-23T15:29:54.402235Z","shell.execute_reply.started":"2023-10-23T15:29:53.313272Z"},"trusted":true},"outputs":[],"source":["plot_s2_img(s2_img[INDEX_IN_BATCH],2,3)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-10-23T15:29:54.405646Z","iopub.status.busy":"2023-10-23T15:29:54.405148Z","iopub.status.idle":"2023-10-23T15:29:54.424415Z","shell.execute_reply":"2023-10-23T15:29:54.423414Z","shell.execute_reply.started":"2023-10-23T15:29:54.405610Z"},"trusted":true},"outputs":[],"source":["torch.sum(output, dim=1) # if all values are 1, then the softmax is working correctly"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-10-23T15:29:54.425730Z","iopub.status.busy":"2023-10-23T15:29:54.425488Z","iopub.status.idle":"2023-10-23T15:29:54.432439Z","shell.execute_reply":"2023-10-23T15:29:54.431507Z","shell.execute_reply.started":"2023-10-23T15:29:54.425709Z"},"trusted":true},"outputs":[],"source":["output = output[INDEX_IN_BATCH].cpu().detach().numpy()\n","output.shape"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-10-23T15:29:54.435427Z","iopub.status.busy":"2023-10-23T15:29:54.435033Z","iopub.status.idle":"2023-10-23T15:29:54.442667Z","shell.execute_reply":"2023-10-23T15:29:54.441875Z","shell.execute_reply.started":"2023-10-23T15:29:54.435394Z"},"trusted":true},"outputs":[],"source":["crop_map = crop_map[INDEX_IN_BATCH].cpu().detach().numpy()\n","crop_map.shape\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-10-23T15:29:54.444095Z","iopub.status.busy":"2023-10-23T15:29:54.443764Z","iopub.status.idle":"2023-10-23T15:29:54.452948Z","shell.execute_reply":"2023-10-23T15:29:54.452174Z","shell.execute_reply.started":"2023-10-23T15:29:54.444062Z"},"trusted":true},"outputs":[],"source":["import matplotlib.pyplot as plt\n","\n","def plot_output_crop_map(output, crop_map):\n","    \"\"\"\n","    Plot the model output and crop map side by side for each band\n","    \n","    Args:\n","    - output: the model output tensor of shape (21, 64, 64)\n","    - crop_map: the crop map tensor of shape (21, 64, 64)\n","    \n","    Returns:\n","    - None\n","    \"\"\"\n","    # Loop over the bands\n","    for i in range(output.shape[0]):\n","        # Create a figure with two subplots\n","        fig, axs = plt.subplots(1, 2, figsize=(10, 5))\n","\n","        # Plot the model output in the first subplot\n","        axs[0].imshow(output[i], cmap='gray')\n","        axs[0].set_title(f'Band {i+1} - Model Output')\n","\n","        # Plot the crop map in the second subplot\n","        axs[1].imshow(crop_map[i], cmap='gray')\n","        axs[1].set_title(f'Band {i+1} - Crop Map')\n","\n","        # Show the plot\n","        plt.show()\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-10-23T15:29:55.233230Z","iopub.status.busy":"2023-10-23T15:29:55.232823Z","iopub.status.idle":"2023-10-23T15:30:04.520314Z","shell.execute_reply":"2023-10-23T15:30:04.519431Z","shell.execute_reply.started":"2023-10-23T15:29:55.233199Z"},"trusted":true},"outputs":[],"source":["plot_output_crop_map(output, crop_map)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"kernelspec":{"display_name":"pytorchGPU","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.16"}},"nbformat":4,"nbformat_minor":4}
